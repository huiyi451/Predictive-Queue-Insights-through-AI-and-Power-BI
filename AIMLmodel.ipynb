{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRiImHWZKQm0"
      },
      "source": [
        "## Linear Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5dGajpFECuv",
        "outputId": "60ac4460-e4a5-4be1-85d1-f16776970116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/25 [==============================] - 1s 9ms/step - loss: 5877.4868 - val_loss: 6071.0869\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5843.2988 - val_loss: 6035.6265\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5808.9131 - val_loss: 6000.4590\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5775.2749 - val_loss: 5964.8926\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5741.0806 - val_loss: 5930.4595\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5707.8394 - val_loss: 5895.3999\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5674.2373 - val_loss: 5861.2202\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5641.2183 - val_loss: 5826.8877\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5608.2075 - val_loss: 5792.9487\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5575.6523 - val_loss: 5758.8501\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5542.8887 - val_loss: 5725.4312\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5510.7383 - val_loss: 5691.7681\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5478.6167 - val_loss: 5658.4238\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5446.5723 - val_loss: 5625.6157\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5414.8481 - val_loss: 5592.9883\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5383.3062 - val_loss: 5560.5967\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5352.2031 - val_loss: 5527.8296\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5320.7500 - val_loss: 5496.0864\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5290.1548 - val_loss: 5463.7271\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5259.1836 - val_loss: 5432.1875\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5228.7671 - val_loss: 5400.5337\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5198.6479 - val_loss: 5368.5356\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5168.0459 - val_loss: 5337.9102\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5138.4419 - val_loss: 5306.5513\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5108.3008 - val_loss: 5276.3545\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5079.0684 - val_loss: 5245.3374\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 5049.4751 - val_loss: 5214.9565\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 5020.3643 - val_loss: 5184.5996\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4991.1367 - val_loss: 5154.8945\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4962.4951 - val_loss: 5124.7539\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4933.9561 - val_loss: 5094.5396\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4905.3022 - val_loss: 5065.0410\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4876.7871 - val_loss: 5036.3145\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4848.7773 - val_loss: 5007.3848\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4821.1099 - val_loss: 4977.8765\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4793.1689 - val_loss: 4949.0454\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4765.6318 - val_loss: 4920.3125\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4738.0293 - val_loss: 4892.2085\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4710.9824 - val_loss: 4863.7847\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4683.7808 - val_loss: 4835.8896\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4656.7954 - val_loss: 4808.3247\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4630.2637 - val_loss: 4780.3452\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4603.7524 - val_loss: 4752.4204\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4577.2520 - val_loss: 4724.9287\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4550.8945 - val_loss: 4697.8931\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 4524.8496 - val_loss: 4670.9653\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4499.0894 - val_loss: 4643.7544\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4473.0391 - val_loss: 4617.4854\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4447.7285 - val_loss: 4590.6470\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 3ms/step - loss: 4422.3281 - val_loss: 4563.9180\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Mean Absolute Error: 54.29348543018103\n",
            "Mean Squared Error: 4563.917652174455\n",
            "R-squared: -1.6012633865312624\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load your dataset (assuming it's in a CSV file)\n",
        "data = pd.read_csv('queue_data.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Remove any unnecessary columns\n",
        "data = data[['date', 'checkin_time', 'checkout_time', 'wait_time','scheduled_appointment', 'first_timer', 'reason_visit', 'specialty',\n",
        "             'gender',  'age', 'number_waiting']]\n",
        "\n",
        "# Encode categorical variables (e.g., gender, specialty, reason_visit)\n",
        "label_encoders = {}\n",
        "categorical_columns = ['gender', 'specialty', 'reason_visit', 'scheduled_appointment', 'first_timer']\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop(columns=['wait_time'])\n",
        "y = data['wait_time']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize/Standardize numerical features (e.g., age)\n",
        "scaler = StandardScaler()\n",
        "X_train[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']] = scaler.fit_transform(X_train[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']])\n",
        "X_test[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']] = scaler.transform(X_test[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']])\n",
        "\n",
        "# Build a linear regression model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "    tf.keras.layers.Dense(1)  # Linear regression output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "linear_mae = mean_absolute_error(y_test, y_pred)\n",
        "linear_mse = mean_squared_error(y_test, y_pred)\n",
        "linear_r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error:\", linear_mae)\n",
        "print(\"Mean Squared Error:\", linear_mse)\n",
        "print(\"R-squared:\", linear_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## LightGBM (Gradient Boosted Tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNz38D1dJmJm",
        "outputId": "d76f0466-20f5-4b5c-f647-bef6225737c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000361 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 266\n",
            "[LightGBM] [Info] Number of data points in the train set: 800, number of used features: 10\n",
            "[LightGBM] [Info] Start training from score 62.576250\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Mean Absolute Error: 1.1210474820801526\n",
            "Mean Squared Error: 19.87588887288816\n",
            "R-squared: 0.9886714822790077\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your data (replace 'your_data.csv' with the actual file path)\n",
        "data = pd.read_csv('queue_data.csv')\n",
        "\n",
        "# Preprocessing\n",
        "label_encoders = {}\n",
        "categorical_features = ['gender', 'specialty', 'scheduled_appointment',\n",
        "                        'first_timer', 'reason_visit']\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    data[feature] = le.fit_transform(data[feature])\n",
        "    label_encoders[feature] = le\n",
        "\n",
        "features = ['date', 'checkin_time', 'checkout_time', 'wait_time', 'gender', 'specialty',\n",
        "            'scheduled_appointment', 'first_timer', 'reason_visit', 'age', 'number_waiting']\n",
        "X = data[features]\n",
        "y = data['wait_time']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a LightGBM dataset\n",
        "train_data = lgb.Dataset(X_train, label=y_train)\n",
        "\n",
        "# Define LightGBM parameters\n",
        "params = {\n",
        "    'objective': 'regression',  # Regression task\n",
        "    'metric': 'l1',  # Mean Absolute Error (MAE) as the evaluation metric\n",
        "    'num_leaves': 31,  # Maximum number of leaves in one tree\n",
        "    'learning_rate': 0.05,  # Learning rate\n",
        "    'feature_fraction': 0.9,  # Fraction of features used in each iteration\n",
        "}\n",
        "\n",
        "# Train the LightGBM model\n",
        "num_round = 100  # Number of boosting rounds (you can tune this)\n",
        "bst = lgb.train(params, train_data, num_round)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = bst.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "gbm_mae = mean_absolute_error(y_test, y_pred)\n",
        "gbm_mse = mean_squared_error(y_test, y_pred)\n",
        "gbm_r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error:\", gbm_mae)\n",
        "print(\"Mean Squared Error:\", gbm_mse)\n",
        "print(\"R-squared:\", gbm_r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_F49W59WDYwR"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w0y62L_DtdR",
        "outputId": "cb90002a-2ef4-4b75-9b4b-a74780222cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Absolute Error: 0.6479500000000005\n",
            "Mean Squared Error: 7.702548500000001\n",
            "R-squared: 0.9956098337167664\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "\n",
        "# Load your dataset (assuming it's in a CSV file)\n",
        "data = pd.read_csv('queue_data.csv')\n",
        "\n",
        "# Preprocess the data\n",
        "# Remove any unnecessary columns\n",
        "data = data[['date', 'checkin_time', 'checkout_time', 'wait_time','scheduled_appointment', 'first_timer', 'reason_visit', 'specialty',\n",
        "             'gender',  'age', 'number_waiting']]\n",
        "\n",
        "# Encode categorical variables (e.g., gender, specialty, reason_visit)\n",
        "label_encoders = {}\n",
        "categorical_columns = ['gender', 'specialty', 'reason_visit', 'scheduled_appointment', 'first_timer']\n",
        "for col in categorical_columns:\n",
        "    le = LabelEncoder()\n",
        "    data[col] = le.fit_transform(data[col])\n",
        "    label_encoders[col] = le\n",
        "\n",
        "# Split the data into features and target\n",
        "X = data.drop(columns=['wait_time'])\n",
        "y = data['wait_time']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normalize/Standardize numerical features (e.g., age)\n",
        "scaler = StandardScaler()\n",
        "X_train[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']] = scaler.fit_transform(X_train[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']])\n",
        "X_test[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']] = scaler.transform(X_test[['age', 'checkin_time', 'checkout_time', 'date', 'number_waiting']])\n",
        "\n",
        "# Build a Random Forest model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest model\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "rf_mae = mean_absolute_error(y_test, y_pred)\n",
        "rf_mse = mean_squared_error(y_test, y_pred)\n",
        "rf_r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Absolute Error:\", rf_mae)\n",
        "print(\"Mean Squared Error:\", rf_mse)\n",
        "print(\"R-squared:\", rf_r2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKJ9g94-axgP"
      },
      "source": [
        "# Evaluation Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0WEm63uNrmP",
        "outputId": "4f818958-c8e7-427b-8537-4d9faa2fd6ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Model      (MAE)        (MSE)      (R²)\n",
            "0  Linear Regression  54.293485  4563.917652 -1.601263\n",
            "1           LightGBM   1.121047    19.875889  0.988671\n",
            "2      Random Forest   0.647950     7.702549  0.995610\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to display the evaluation metrics results\n",
        "results = pd.DataFrame({\n",
        "    'Model': ['Linear Regression', 'LightGBM', 'Random Forest'],\n",
        "    '(MAE)': [linear_mae, gbm_mae, rf_mae],\n",
        "    '(MSE)': [linear_mse, gbm_mse, rf_mse],\n",
        "    '(R²)': [linear_r2, gbm_r2, rf_r2],\n",
        "})\n",
        "\n",
        "# Sort the results DataFrame by the '(R²)' column in ascending order\n",
        "results_sorted = results.sort_values(by='(R²)')\n",
        "\n",
        "# Display the sorted results DataFrame\n",
        "print(results_sorted)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDWyur352h4x"
      },
      "source": [
        "## Predicted Wait Time from trained Random Forest Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgToqv8Vgpxk",
        "outputId": "0b1116cd-6e77-48b3-82e2-16f8678fc4f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     Actual Wait Time  Predicted Wait Time\n",
            "521                33                33.05\n",
            "737                40                39.96\n",
            "740                50                50.02\n",
            "660                28                27.98\n",
            "411                53                52.87\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Load your data (replace 'your_data.csv' with the actual file path)\n",
        "data = pd.read_csv('queue_data.csv')\n",
        "\n",
        "# Assuming you have a DataFrame 'data' with columns:\n",
        "# date, checkin_time, checkout_time, wait_time, gender, specialty, scheduled_appointment,\n",
        "# first_timer, reason_of_visit, age\n",
        "\n",
        "# Preprocessing\n",
        "# Convert categorical variables to numerical using LabelEncoder\n",
        "label_encoders = {}\n",
        "categorical_features = ['gender', 'specialty', 'scheduled_appointment',\n",
        "                        'first_timer', 'reason_visit']\n",
        "for feature in categorical_features:\n",
        "    le = LabelEncoder()\n",
        "    data[feature] = le.fit_transform(data[feature])\n",
        "    label_encoders[feature] = le\n",
        "\n",
        "# Assuming you want to predict 'wait_time'\n",
        "features = ['date', 'checkin_time', 'checkout_time', 'gender', 'specialty',\n",
        "            'scheduled_appointment', 'first_timer', 'reason_visit', 'age', 'number_waiting']\n",
        "X = data[features]\n",
        "y = data['wait_time']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build and train a Random Forest model\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Show the results (predicted wait time alongside actual wait time)\n",
        "results = pd.DataFrame({'Actual Wait Time': y_test, 'Predicted Wait Time': y_pred})\n",
        "print(results.head())  # Display the first few rows of results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ4KOxOM2zCf"
      },
      "source": [
        "## Average Predicted Wait Time according to Number Waiting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOvWPkPxgxFI",
        "outputId": "f75770ec-6ad8-4c27-c653-6f9ecb5967c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    number_waiting  Average Predicted Wait Time\n",
            "0                1                    12.907143\n",
            "1                2                    20.778276\n",
            "2                3                    28.317143\n",
            "3                4                    34.040625\n",
            "4                5                    39.486923\n",
            "5                6                    44.223333\n",
            "6                7                    50.628421\n",
            "7                9                    89.020000\n",
            "8               11                   110.010000\n",
            "9               12                   112.192500\n",
            "10              13                   126.444444\n",
            "11              14                   131.295714\n",
            "12              15                   139.836667\n",
            "13              18                   155.290000\n",
            "14              20                   209.600000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already made predictions and have a DataFrame 'results' with 'Actual Wait Time' and 'Predicted Wait Time'\n",
        "# Also, 'X_test' should have a 'number_waiting' feature\n",
        "\n",
        "# Create a DataFrame combining the actual and predicted wait times with 'number_waiting'\n",
        "results_with_number_waiting = pd.concat([results, X_test['number_waiting']], axis=1)\n",
        "\n",
        "# Group by 'number_waiting' and calculate the mean predicted wait time for each group\n",
        "average_predicted_wait_time = results_with_number_waiting.groupby('number_waiting')['Predicted Wait Time'].mean().reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "average_predicted_wait_time.columns = ['number_waiting', 'Average Predicted Wait Time']\n",
        "\n",
        "# Display the average predicted wait time for each group as a table\n",
        "print(average_predicted_wait_time)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJkwzCWt2_mH"
      },
      "source": [
        "### Linear Regression model for Average Wait Time Prediction of Number Waiting from 21 to 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NGs62sbzOMj",
        "outputId": "2401bf3a-a2c0-4c8f-80db-2ff81d2c364d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   number_waiting  Average Predicted Wait Time\n",
            "0              21                   203.283406\n",
            "1              22                   213.295817\n",
            "2              23                   223.308227\n",
            "3              24                   233.320637\n",
            "4              25                   243.333048\n",
            "5              26                   253.345458\n",
            "6              27                   263.357869\n",
            "7              28                   273.370279\n",
            "8              29                   283.382689\n",
            "9              30                   293.395100\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Assuming you already have the 'average_predicted_wait_time' DataFrame\n",
        "\n",
        "# Extract relevant data\n",
        "X = average_predicted_wait_time[['number_waiting']]\n",
        "y = average_predicted_wait_time['Average Predicted Wait Time']\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train a linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict average wait times for 'number_waiting' values in the range 21 to 30\n",
        "number_waiting_range = list(range(21, 31))\n",
        "predicted_wait_times = model.predict(pd.DataFrame(number_waiting_range, columns=['number_waiting']))\n",
        "\n",
        "# Create a DataFrame to display the predictions in a table\n",
        "prediction_table = pd.DataFrame({'number_waiting': number_waiting_range, 'Average Predicted Wait Time': predicted_wait_times})\n",
        "\n",
        "# Display the prediction table\n",
        "print(prediction_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlWKuDOO0US3",
        "outputId": "2bf9fd82-58a1-497c-97ed-a9e7c3eab4a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    number_waiting  Average Predicted Wait Time\n",
            "0                1                        12.91\n",
            "1                2                        20.78\n",
            "2                3                        28.32\n",
            "3                4                        34.04\n",
            "4                5                        39.49\n",
            "5                6                        44.22\n",
            "6                7                        50.63\n",
            "7                9                        89.02\n",
            "8               11                       110.01\n",
            "9               12                       112.19\n",
            "10              13                       126.44\n",
            "11              14                       131.30\n",
            "12              15                       139.84\n",
            "13              18                       155.29\n",
            "14              20                       209.60\n",
            "0               21                       203.28\n",
            "1               22                       213.30\n",
            "2               23                       223.31\n",
            "3               24                       233.32\n",
            "4               25                       243.33\n",
            "5               26                       253.35\n",
            "6               27                       263.36\n",
            "7               28                       273.37\n",
            "8               29                       283.38\n",
            "9               30                       293.40\n"
          ]
        }
      ],
      "source": [
        "# Assuming you already have prediction tables for two scenarios: prediction_table1 and prediction_table2\n",
        "\n",
        "# Combine the two prediction tables into one\n",
        "combined_prediction_table = pd.concat([average_predicted_wait_time, prediction_table])\n",
        "\n",
        "# Round the 'Predicted Wait Time' column to two decimal places\n",
        "combined_prediction_table['Average Predicted Wait Time'] = combined_prediction_table['Average Predicted Wait Time'].round(2)\n",
        "\n",
        "# Display the combined and rounded prediction table\n",
        "print(combined_prediction_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs13YWRf03zp",
        "outputId": "4c3ebce9-0c9a-4597-85d8-6d7a26964f6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combined table has been exported to predicted_table.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have the combined_table DataFrame\n",
        "\n",
        "# Specify the file path for the CSV file\n",
        "csv_file_path = 'predicted_table.csv'\n",
        "\n",
        "# Export the DataFrame to a CSV file\n",
        "combined_prediction_table.to_csv(csv_file_path, index=False)\n",
        "\n",
        "print(f\"Combined table has been exported to {csv_file_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
